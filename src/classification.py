import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score

# Importing the dataset
csv_path = "/media/sandeep/DATA/raw_final_dataset/Various_samples_header_features.csv"
dataset = pd.read_csv(csv_path)
X = dataset.drop(['md5', 'e_res', 'e_res2', 'class'], axis=1).values
y = dataset['class'].values

# Tree-based feature selection:
from sklearn.feature_selection import SelectFromModel
import sklearn.ensemble as ske

fsel = ske.ExtraTreesClassifier().fit(X, y)
model = SelectFromModel(fsel, prefit=True)
X_new = model.transform(X)
# nb_features = X_new.shape[1]
# indices = np.argsort(fsel.feature_importances_)[::-1][:nb_features]
# for f in range(nb_features):
#     print("%d. feature %s (%f)" % (f + 1, dataset.columns[2 + indices[f]], fsel.feature_importances_[indices[f]]))
# features = []
# for f in sorted(np.argsort(fsel.feature_importances_)[::-1][:nb_features]):
#     features.append(dataset.columns[2 + f])

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.20, random_state=0)

# Feature Scaling
from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# ------------------------K-NN--------------------------------------
from sklearn.neighbors import KNeighborsClassifier

# classifier = KNeighborsClassifier(n_neighbors=3, metric='minkowski', p=2)
# classifier.fit(X_train, y_train)
#
# # Predicting the Test set results
# y_pred = classifier.predict(X_test)

# acc = accuracy_score(y_test, y_pred)
# print(acc)


# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix

# cm = confusion_matrix(y_test, y_pred)
# print(cm)
#
# score = KNeighborsClassifier.score(X_test, y_test)
# print(score)
# ------------------------------------------------------------------

# -----------------Random-Forest------------------------------------
from sklearn.ensemble import RandomForestClassifier

classifier = RandomForestClassifier(n_estimators=50, criterion='entropy')
classifier.fit(X_train, y_train)

# predict the test results
y_pred = classifier.predict(X_test)

acc = accuracy_score(y_test, y_pred)
print("Accuracy: ", acc)

# Makeing the confusion matrix
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)
print(cm)
# # ------------------------------------------------------------------
#
# # -------------------XGBoost----------------------------------------
# from xgboost import XGBClassifier
#
# classifier = XGBClassifier(max_depth=10, learning_rate=0.1, n_estimators=50)
# classifier.fit(X_train, y_train)
#
# # predict the test results
# y_pred = classifier.predict(X_test)
#
# acc = accuracy_score(y_test, y_pred)
# print("Accuracy: ", acc)
#
# # from sklearn.model_selection import cross_val_score
# # accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)
# # print(accuracies.mean())
# # accuracies.std()
#
# # # Makeing the confusion matrix
# from sklearn.metrics import confusion_matrix
#
# cm = confusion_matrix(y_test, y_pred)
# print(cm)
# -----------------------------------------------------------------