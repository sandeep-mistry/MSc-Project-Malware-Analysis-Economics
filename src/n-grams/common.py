import os
import shutil
import pandas as pd
import pickle
from operator import itemgetter
from collections import OrderedDict
import itertools


# Delete path if exists
def deleteIfExists(filename):
    if os.path.exists(filename):
        os.remove(filename)


# Delete directory and create a new one  
def clearPath(dirPath):
    if os.path.exists(dirPath):
        shutil.rmtree(dirPath)
    os.makedirs(dirPath)


# Export extraction times to .dat file
def extraction_time_export(filename, extraction_time):
    extraction_times = []
    output_filename = filename
    if os.path.exists(output_filename):
        with open(output_filename, 'rb') as rfp:
            extraction_times = pickle.load(rfp)
    extraction_times.append(extraction_time)
    with open(output_filename, 'wb') as wfp:
        pickle.dump(extraction_times, wfp)


# Get top 'k' n-grams occurrences
def get_top_n_grams_features(feat_files, gram, num_features):
    dictionaries = []
    for file in feat_files:
        res = [pickle.load(open(file, "rb"))]
        byte_dictionary = [item[gram] for item in res]
        for entry in byte_dictionary:
            new_byte_dictionary = entry

        sorted_dictionary = dict(OrderedDict(sorted(new_byte_dictionary.items(), key=itemgetter(1), reverse=True)))
        byte_dictionary = dict(itertools.islice(sorted_dictionary.items(), num_features))
        dictionaries.append(byte_dictionary)
    return dictionaries


# Global paths
root_path = "/home/sandeep/outputs/"
train_dir = "/mnt/disks/data/hexdumps/all-hexdumps/"
labels_path = "/home/sandeep/Labels.csv"

# Multi-threading
# numWorkers = 8

dataset = [os.path.join(train_dir, f) for f in os.listdir(train_dir) if
             os.path.isfile(os.path.join(train_dir, f))]

label_data = pd.read_csv(labels_path)
labels = {row['MD5hash']: row['ClassLabel'] for index, row in label_data.iterrows()}
train_label = [labels[i.split(os.sep)[-1].split(".")[0]] - 1 for i in dataset]

model_dir = os.path.join(root_path, "model")
feat_dir = os.path.join(root_path, "feat")
time_dir_bytes = os.path.join(root_path, 'extraction_times_bytes')
time_dir_feature_matrices = os.path.join(root_path, 'extraction_times_feature_matrices')

# Byte paths
byte_feat_dir = os.path.join(feat_dir, "byte")
byte1g_matrix_path = os.path.join(model_dir, "byte1g_matrix.npy")
byte2g_matrix_path = os.path.join(model_dir, "byte2g_matrix.npz")
byte3g_matrix_path = os.path.join(model_dir, "byte3g_matrix.npz")
byte4g_matrix_path = os.path.join(model_dir, "byte4g_matrix.npz")

# Important features paths
byte2g_imp_feature_path = os.path.join(model_dir, "byte2g_imp_feature")
byte3g_imp_feature_path = os.path.join(model_dir, "byte3g_imp_feature")
byte1g_imp_feature_path = os.path.join(model_dir, "byte1g_imp_feature")
