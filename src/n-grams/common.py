import random
import os
import shutil
import Reader as r
import pandas as pd


# Delete path if exists
def deleteIfExists(filename):
    if os.path.exists(filename):
        os.remove(filename)


# Delete directory and create a new one  
def clearPath(dirPath):
    if os.path.exists(dirPath):
        shutil.rmtree(dirPath)
    os.makedirs(dirPath)


# Global paths
root_path = "/media/sandeep/DATA/raw_final_dataset/Hexdumps/"
train_dir = "/media/sandeep/DATA/raw_final_dataset/Hexdumps/train_set/"
numWorkers = 4
subset_size = 100

dataset = [os.path.join(train_dir, f) for f in os.listdir(train_dir) if
             os.path.isfile(os.path.join(train_dir, f))]

train_set = dataset

csv_path = "/media/sandeep/DATA/raw_final_dataset/Labels.csv"
label_data = pd.read_csv(csv_path)
labels = {row['MD5hash']: row['ClassLabel'] for index, row in label_data.iterrows()}

train_label = [labels[i.split(os.sep)[-1].split(".")[0]] - 1 for i in train_set]

model_dir = os.path.join(root_path, "model")
feat_dir = os.path.join(root_path, "feat")

# Byte paths
byte_feat_dir = os.path.join(feat_dir, "byte")
byte1g_matrix_path = os.path.join(model_dir, "byte1g_matrix.npy")
byte1f_matrix_path = os.path.join(model_dir, "byte1f_matrix.npy")
byte2g_matrix_path = os.path.join(model_dir, "byte2g_matrix.npy")
byte3g_matrix_path = os.path.join(model_dir, "byte3g_matrix.npz")
byte4g_matrix_path = os.path.join(model_dir, "byte4g_matrix.npz")

# Important features paths
byte2g_imp_feature_path = os.path.join(model_dir, "byte2g_imp_feature")
byte3g_imp_feature_path = os.path.join(model_dir, "byte3g_imp_feature")
byte1g_imp_feature_path = os.path.join(model_dir, "byte1g_imp_feature")

final_classifier_path = os.path.join(root_path, "final_classifier")

# Selected features paths
selected_features_path = os.path.join(root_path, "selected_features")
