import numpy as np
from common import *
from Grebber import chunks
from multiprocessing import Process
from scipy.stats import entropy
import Reader as r
import pickle
from progressbar import Percentage, Bar, ProgressBar, ETA
import sys
import time
import csv
import os.path
import pandas as pd
from tablib import Dataset
import pickle


def byteEntropy(byteFreq):
    probs = np.array(byteFreq)
    probs = probs / probs.sum()
    ent = entropy(probs)
    return ent


def findIndex(lst):
    res = 0
    for idx, val in enumerate(lst):
        res += val * (257 ** idx)
    return res


def byteSeqToInt(seq):
    bytes = []
    for row in seq:
        for item in row.split(' ')[1:]:
            if item != "??":
                bytes.append(int(item, 16))
            else:
                bytes.append(256)
    return bytes


def processFile(text):
    bytes = byteSeqToInt(text)

    if __name__ == "__main__":

        if sys.argv[1] == "1":
            # 1gram
            byte1gram = [0] * 257
            for item in bytes:
                byte1gram[item] += 1
            res = {'1g': byte1gram}

        elif sys.argv[1] == "2":
            # 2gram
            n = 2
            byte2gram = {}
            for i in range(len(bytes)-n+1):
                idx = findIndex(bytes[i:i+n])
                byte2gram[idx] = byte2gram.get(idx, 0) + 1
            res = {'2g': byte2gram}

        elif sys.argv[1] == "3":
            # 3gram
            n = 3
            byte3gram = {}
            for i in range(len(bytes)-n+1):
                idx = findIndex(bytes[i:i+n])
                byte3gram[idx] = byte3gram.get(idx, 0) + 1
            res = {'3g': byte3gram}

        else:
            print("Invalid entry")
            exit()

    return res


def worker(chunk, output_dir):
    widgets = ['Worker {}: '.format(chunk[0]), ' ', Percentage(), ' ', Bar(), ' ', ETA()]
    pbar = ProgressBar(widgets=widgets, maxval=len(chunk[1])).start()
    for idx, item in enumerate(chunk[1]):
        fn = item.split(os.sep)[-1].split(".")[0]

        # Save data
        data = processFile(r.readBytes(item))
        pickle.dump(data, open(os.path.join(output_dir, fn), "wb"))

        # Update progressbar
        pbar.update(idx + 1)
    pbar.finish()


main_path = os.path.join(root_path, "train")
split_data = chunks(train_set, numWorkers)
output_dir = os.path.join(main_path, byte_feat_dir)

clearPath(output_dir)

# Prepare csv file
output_csv = "/media/sandeep/DATA/raw_final_dataset/n_grams_feature_extraction_times.csv"
f = open(output_csv, mode="w")
file_exists = os.path.isfile(output_csv)

with open(output_csv, 'a') as csvfile:
    writer = csv.writer(f, delimiter=',')
    field_names = ["1 gram", "2 gram", "3 gram"]

    if not file_exists:
        writer.writeheader()  # file doesn't exist yet, write a header
    writer.writerow(field_names)


jobs = []
start_time = time.time()
print("Byte feature extraction started!")
for item in enumerate(split_data):
    p = Process(target=worker, args=(item, output_dir))
    jobs.append(p)
    p.start()

for j in jobs:
    j.join()

print("Byte feature extraction completed!")

if __name__ == "__main__":

    if sys.argv[1] == "1":
        extraction_time_1g = time.time() - start_time
        extraction_times = []
        filename = '1_gram.dat'
        if os.path.exists(filename):
            with open(filename, 'rb') as rfp:
                extraction_times = pickle.load(rfp)
        extraction_times.append(extraction_time_1g)
        with open(filename, 'wb') as wfp:
            pickle.dump(extraction_times, wfp)

    elif sys.argv[1] == "2":
        extraction_time_2g = time.time() - start_time
        extraction_times = []
        filename = '2_gram.dat'
        if os.path.exists(filename):
            with open(filename, 'rb') as rfp:
                extraction_times = pickle.load(rfp)
        extraction_times.append(extraction_time_2g)
        with open(filename, 'wb') as wfp:
            pickle.dump(extraction_times, wfp)

    elif sys.argv[1] == "3":
        extraction_time_3g = time.time() - start_time
        extraction_times = []
        filename = '3_gram.dat'
        if os.path.exists(filename):
            with open(filename, 'rb') as rfp:
                extraction_times = pickle.load(rfp)
        extraction_times.append(extraction_time_3g)
        with open(filename, 'wb') as wfp:
            pickle.dump(extraction_times, wfp)

        f.close()

    else:
        exit()
