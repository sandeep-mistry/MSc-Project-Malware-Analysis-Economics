import scipy.sparse
import sys
import time
import csv
import numpy as np
from xgboost import XGBClassifier
from common import *
from sklearn.feature_selection import SelectKBest, f_regression, SelectFromModel, chi2
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score
from sklearn.neural_network import MLPClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score

# Path names
main_path = root_path
byte1g_matrix_path = os.path.join(main_path, byte1g_matrix_path)
byte2g_matrix_path = os.path.join(main_path, byte2g_matrix_path)
byte3g_matrix_path = os.path.join(main_path, byte3g_matrix_path)

rfc = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)
sfm = SelectFromModel(rfc, threshold=2e-5)


def roc_auc_score_multiclass(actual_class, pred_class, average="macro"):
    # creating a set of all the unique classes using the actual class list
    unique_class = set(actual_class)
    roc_auc_dict = {}
    for per_class in unique_class:
        # creating a list of all the classes except the current class
        other_class = [x for x in unique_class if x != per_class]

        # marking the current class as 1 and all other classes as 0
        new_actual_class = [0 if x in other_class else 1 for x in actual_class]
        new_pred_class = [0 if x in other_class else 1 for x in pred_class]

        # using the sklearn metrics method to calculate the roc_auc_score
        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average=average)
        roc_auc_dict[per_class] = roc_auc

    return roc_auc_dict


def classify(training_matrix, classifier):
    X_train, X_test, y_train, y_test = train_test_split(training_matrix, train_label, test_size=0.2, random_state=7)
    kfold = KFold(n_splits=10, random_state=7)
    print("Fitting classifier")
    classifier.fit(X_train, y_train)
    # predict the test results
    cross_val_results = cross_val_score(classifier, X_train, y_train, cv=kfold) * 100
    cross_val_mean = np.mean(cross_val_results)
    cross_val_variance = np.var(cross_val_results)
    y_pred = classifier.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred) * 100
    # confusion_mat = confusion_matrix(y_test, y_pred)
    auc_score = roc_auc_score_multiclass(y_test, y_pred)
    return [accuracy, auc_score, cross_val_results, cross_val_mean, cross_val_variance]


classifier_names = ["Random Forest", "Naive Bayes", "XGBoost", "KNN", "MLP"]

classifiers = [
    RandomForestClassifier(n_estimators=50, criterion='entropy', random_state=7),
    MultinomialNB(),
    XGBClassifier(max_depth=20, learning_rate=0.3, n_estimators=150),
    KNeighborsClassifier(5),
    MLPClassifier(alpha=1, max_iter=1000)]

# Prepare csv file

if __name__ == "__main__":

    if sys.argv[1] == "1gram":
        output_csv = "/home/sandeep/outputs/1_gram_classifier_accuracies.csv"
    elif sys.argv[1] == "2gram":
        output_csv = "/home/sandeep/outputs/2_gram_classifier_accuracies.csv"
    elif sys.argv[1] == "3gram":
        output_csv = "/home/sandeep/outputs/3_gram_classifier_accuracies.csv"
    else:
        print("Invalid argument! Enter '1gram', '2gram' or '3gram'.")
        exit()


def multiple_classifications(clf_names, clfs):
    f = open(output_csv, mode="w", encoding='utf-8')
    writer = csv.writer(f, delimiter=',')
    writer.writerow(['Classifier'] + ['Accuracy'] + ['AUC Score'] + ['Cross Val Score'] + ['Cross Val Mean'] + \
                    ['Cross Val Variance'])

    for name, clf in zip(clf_names, clfs):
        classification_scores = classify(final_train_matrix, clf)
        writer.writerow([name] + [str(classification_scores[0])] + [str(classification_scores[1])] + \
                                [str(classification_scores[2])] + [str(classification_scores[3])] + \
                                [str(classification_scores[4])])
    f.close()


start_time = time.time()

if __name__ == "__main__":

    if sys.argv[1] == "1gram":
        print("Byte 1gram started")
        byte1g_matrix = np.load(byte1g_matrix_path)
        final_train_matrix = byte1g_matrix
        multiple_classifications(classifier_names, classifiers)

    elif sys.argv[1] == "2gram":
        print("Byte 2gram started")
        byte2g_matrix = scipy.sparse.load_npz(byte2g_matrix_path)
        sfm.fit(byte2g_matrix, train_label)
        byte2g_important_matrix = sfm.transform(byte2g_matrix)
        extraction_time_2g_sfm = time.time() - start_time
        extraction_time_export('2_gram_sfm.dat', extraction_time_2g_sfm)
        final_train_matrix = byte2g_important_matrix
        del byte2g_matrix
        multiple_classifications(classifier_names, classifiers)

    elif sys.argv[1] == "3gram":
        print("Byte 3gram started")
        byte3g_matrix = scipy.sparse.load_npz(byte3g_matrix_path)
        final_train_matrix = byte3g_matrix
        sfm.fit(byte3g_matrix, train_label)
        byte3g_important_matrix = sfm.transform(byte3g_matrix)
        extraction_time_3g_sfm = time.time() - start_time
        extraction_time_export('3_gram_sfm.dat', extraction_time_3g_sfm)
        final_train_matrix = byte3g_important_matrix
        del byte3g_matrix
        multiple_classifications(classifier_names, classifiers)

    else:
        print("Invalid argument! Enter '1gram', '2gram' or '3gram'.")
        exit()
