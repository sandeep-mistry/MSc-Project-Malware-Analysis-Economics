from common import *
from sklearn.feature_extraction import DictVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import normalize
import numpy as np
import pickle
import sys

if __name__ == "__main__":

    # Which dataset? Training or testing?
    if sys.argv[1] == "train":
        main_path = os.path.join(root_path, "train")
        t = train_set
    else:
        main_path = os.path.join(root_path, "test")
        t = test_set

    # Boring path names
    model_dir = os.path.join(main_path, model_dir)

    byte_feat_dir = os.path.join(main_path, byte_feat_dir)
    byte1g_matrix_path = os.path.join(main_path, byte1g_matrix_path)
    byte1f_matrix_path = os.path.join(main_path, byte1f_matrix_path)
    byte2g_matrix_path = os.path.join(main_path, byte2g_matrix_path)
    byte4g_matrix_path = os.path.join(main_path, byte4g_matrix_path)
    # There is a bug of pickle for overwriting previous files if newer file is smaller
    # So just clear the folder!
    clearPath(model_dir)

    #############################   BYTE FEATURES   ###########################################################
    print("Byte features started")
    # Load features
    feat_files = [os.path.join(byte_feat_dir, file.split(os.sep)[-1].split(".")[0]) for file in t]
    # res = [pickle.load(open(file, "rb")) for file in feat_files]

    # 1gram
    byte1g_matrix = np.array([pickle.load(open(file, "rb"))['1g'] for file in feat_files])
    byte1g_matrix = normalize(byte1g_matrix, axis=1, norm='l1')
    np.save(byte1g_matrix_path, byte1g_matrix)
    del byte1g_matrix

    # 1gram entropy
    byte1f_matrix = np.array([pickle.load(open(file, "rb"))['1f'] for file in feat_files])
    np.save(byte1f_matrix_path, byte1f_matrix)
    del byte1f_matrix

    # 2gram
    # byte2g_dicts = np.array([pickle.load(open(file, "rb"))['2g'] for file in feat_files])
    # dictVectorizer = DictVectorizer()
    # byte2g_matrix = dictVectorizer.fit_transform(byte2g_dicts)
    # byte2g_matrix = normalize(byte2g_matrix, axis=1, norm='l1')
    # feat_names = dictVectorizer.get_feature_names()
    # np.save(byte2g_matrix_path, byte2g_matrix)
    # del byte2g_matrix

    # 4gram
    # byte4g_dicts = [item['4g'] for item in res]
    # del res
    # dictVectorizer = DictVectorizer(sparse=True)
    # byte4g_matrix = dictVectorizer.fit_transform(byte4g_dicts)
    # feat_names = dictVectorizer.get_feature_names()
    # np.save(byte4g_matrix_path, byte4g_matrix)
    # del byte4g_matrix
    # del byte4g_dicts
