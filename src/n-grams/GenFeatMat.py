from common import *
from sklearn.feature_extraction import DictVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import normalize
import numpy as np
import pickle
import sys
import scipy.sparse
import scipy

main_path = os.path.join(root_path, "train")
t = train_set

# Boring path names
model_dir = os.path.join(main_path, model_dir)
byte_feat_dir = os.path.join(main_path, byte_feat_dir)
byte1g_matrix_path = os.path.join(main_path, byte1g_matrix_path)
byte1f_matrix_path = os.path.join(main_path, byte1f_matrix_path)
byte2g_matrix_path = os.path.join(main_path, byte2g_matrix_path)
byte3g_matrix_path = os.path.join(main_path, byte3g_matrix_path)
byte4g_matrix_path = os.path.join(main_path, byte4g_matrix_path)

# There is a bug of pickle for overwriting previous files if newer file is smaller
# So just clear the folder!
#clearPath(model_dir)

#############################   BYTE FEATURES   ###########################################################
print("Byte features started")
# Load features
feat_files = [os.path.join(byte_feat_dir, file.split(os.sep)[-1].split(".")[0]) for file in t]
res = [pickle.load(open(file, "rb"), encoding='latin1') for file in feat_files]

# 1gram
# byte1g_matrix = np.array([pickle.load(open(file, "rb"), encoding='latin1')['1g'] for file in feat_files])
# byte1g_matrix = normalize(byte1g_matrix, axis=1, norm='l1')
# np.save(byte1g_matrix_path, byte1g_matrix)
# del byte1g_matrix

# # 1gram entropy
# byte1f_matrix = np.array([pickle.load(open(file, "rb"))['1f'] for file in feat_files])
# np.save(byte1f_matrix_path, byte1f_matrix)
# del byte1f_matrix
# byte1g_matrix = np.array([pickle.load(open(file, "rb"))['1g'] for file in feat_files])
# byte1g_matrix = normalize(byte1g_matrix, axis=1, norm='l1')
# np.save(byte1g_matrix_path, byte1g_matrix)
# del byte1g_matrix

# 2gram
# byte2g_dicts = np.array([pickle.load(open(file, "rb"), encoding='latin1')['2g'] for file in feat_files])
# dictVectorizer = DictVectorizer(sparse=True)
# byte2g_matrix = dictVectorizer.fit_transform(byte2g_dicts)
# byte2g_matrix = normalize(byte2g_matrix, axis=1, norm='l1')
# byte2g_matrix = byte2g_matrix.toarray()
# feat_names = dictVectorizer.get_feature_names()
# np.save(byte2g_matrix_path, byte2g_matrix)
# del byte2g_matrix

# 3gram
byte3g_dicts = [item['3g'] for item in res]
del res
dictVectorizer = DictVectorizer(sparse=True)
byte3g_matrix = dictVectorizer.fit_transform(byte3g_dicts).tocsr()
scipy.sparse.save_npz(byte3g_matrix_path, byte3g_matrix)
feat_names = dictVectorizer.get_feature_names()
del byte3g_matrix
del byte3g_dicts

# 4gram
# byte4g_dicts = [item['4g'] for item in res]
# del res
# dictVectorizer = DictVectorizer(sparse=True)
# byte4g_matrix = dictVectorizer.fit_transform(byte4g_dicts)
# feat_names = dictVectorizer.get_feature_names()
# np.save(byte4g_matrix_path, byte4g_matrix)
# del byte4g_matrix
# del byte4g_dicts
