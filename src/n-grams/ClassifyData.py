import scipy.sparse
import sys
import time
import csv
import numpy as np
from xgboost import XGBClassifier
from common import *
from sklearn.feature_selection import SelectKBest, f_regression, SelectFromModel, chi2
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,ExtraTreesClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score


# Path names
main_path = root_path
byte1g_matrix_path = os.path.join(main_path, byte1g_matrix_path)
byte2g_matrix_path = os.path.join(main_path, byte2g_matrix_path)
byte3g_matrix_path = os.path.join(main_path, byte3g_matrix_path)

rfc = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)
sfm = SelectFromModel(rfc, threshold=2e-5)

start_time = time.time()

if __name__ == "__main__":

    if sys.argv[1] == "1gram":
        print("Byte 1gram started")
        byte1g_matrix = np.load(byte1g_matrix_path)
        final_train_matrix = byte1g_matrix

    elif sys.argv[1] == "2gram":
        print("Byte 2gram started")
        byte2g_matrix = scipy.sparse.load_npz(byte2g_matrix_path)
        sfm.fit(byte2g_matrix, train_label)
        byte2g_important_matrix = sfm.transform(byte2g_matrix)
        final_train_matrix = byte2g_important_matrix
        del byte2g_matrix

    elif sys.argv[1] == "3gram":
        print("Byte 3gram started")
        byte3g_matrix = scipy.sparse.load_npz(byte3g_matrix_path)
        sfm.fit(byte3g_matrix, train_label)
        byte3g_important_matrix = sfm.transform(byte3g_matrix)
        final_train_matrix = byte3g_important_matrix
        del byte3g_matrix

    else:
        print("Invalid argument! Enter '1gram', '2gram' or '3gram'.")
        exit()


def classify(training_matrix, classifier):
    X_train, X_test, y_train, y_test = train_test_split(training_matrix, train_label, test_size=0.2, random_state=7)
    print("Fitting classifier")
    classifier.fit(X_train, y_train)
    # predict the test results
    y_pred = classifier.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    # confusion_mat = confusion_matrix(y_test, y_pred)
    auc_score = roc_auc_score(y_test, y_pred)
    return [accuracy, auc_score]


classifier_names = ["Random Forest", "Gradient Boosting", "Linear SVM", "XGBoost", "KNN", "MLP"]

classifiers = [
    RandomForestClassifier(n_estimators=50, criterion='entropy', random_state=7),
    GradientBoostingClassifier(n_estimators=400, max_features=5, verbose=1),
    SVC(kernel="linear"),
    XGBClassifier(max_depth=20, learning_rate=0.3, n_estimators=150),
    KNeighborsClassifier(5),
    MLPClassifier(alpha=1, max_iter=1000)]

# Prepare csv file
output_csv = "/home/sandeep/outputs/classifier_accuracies_times.csv"
f = open(output_csv, mode="w", encoding='utf-8')
writer = csv.writer(f, delimiter=',')
writer.writerow(['Classifier'] + ['Accuracy'] + ['AUC Score'] + ['Classification Time'])

for name, clf in zip(classifier_names, classifiers):
    classification_scores = classify(final_train_matrix, clf)
    writer.writerow(name + classification_scores)
f.close()
